{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scanpy --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkxK46YGGGI6",
        "outputId": "2c3841f3-728f-4f0e-e889-e68e9ccb9698"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for session-info (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://plus.figshare.com/ndownloader/files/35775512"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lHLb9eHGPvq",
        "outputId": "85b50cc3-9384-464c-c500-4136c7bc2bd2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-23 21:47:27--  https://plus.figshare.com/ndownloader/files/35775512\n",
            "Resolving plus.figshare.com (plus.figshare.com)... 34.248.227.16, 54.155.30.132, 2a05:d018:1f4:d003:d918:7b0f:e20c:de02, ...\n",
            "Connecting to plus.figshare.com (plus.figshare.com)|34.248.227.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://s3-eu-west-1.amazonaws.com/pstorage-plus-7003492043/35775512/rpe1_normalized_bulk_01.h5ad?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA3OGA3B5WLN3GODUZ/20240123/eu-west-1/s3/aws4_request&X-Amz-Date=20240123T214727Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=131347f20d8271f82155e9a5f9618ede3cf957d4f68ea43df4cfe472b8962744 [following]\n",
            "--2024-01-23 21:47:27--  https://s3-eu-west-1.amazonaws.com/pstorage-plus-7003492043/35775512/rpe1_normalized_bulk_01.h5ad?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA3OGA3B5WLN3GODUZ/20240123/eu-west-1/s3/aws4_request&X-Amz-Date=20240123T214727Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=131347f20d8271f82155e9a5f9618ede3cf957d4f68ea43df4cfe472b8962744\n",
            "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.88.35, 52.218.29.19, 52.92.33.240, ...\n",
            "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.88.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 95350546 (91M) [application/octet-stream]\n",
            "Saving to: ‘35775512’\n",
            "\n",
            "35775512            100%[===================>]  90.93M  26.1MB/s    in 3.9s    \n",
            "\n",
            "2024-01-23 21:47:32 (23.6 MB/s) - ‘35775512’ saved [95350546/95350546]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RrTy4V5PEAXx"
      },
      "outputs": [],
      "source": [
        "import scanpy as sc\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adata_orig = sc.read_h5ad(\"35775512\")\n",
        "adata_orig.X[adata_orig.X == float(\"inf\")]=0"
      ],
      "metadata": {
        "id": "YlPlde8NGBam"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "std_=adata_orig.X.std(axis=0)\n",
        "mean_=adata_orig.X.mean(axis=0)"
      ],
      "metadata": {
        "id": "8kGzU6OxT2te"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MuMSKcilUUDd"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import tqdm\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "\n",
        "\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
      ],
      "metadata": {
        "id": "7v1T3KqDGLV7"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class X_dataset(Dataset):\n",
        "    def __init__(self,data):\n",
        "        self.data=data\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        return {'x':torch.tensor((self.data.X[idx]-mean_)/std_),'c':torch.tensor(self.data.obs.iloc[idx]['core_control'])}\n"
      ],
      "metadata": {
        "id": "xWjJL1iDIqDY"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=X_dataset(adata_orig)\n",
        "train_loader=DataLoader(dataset,batch_size=32,shuffle=True,drop_last=True)"
      ],
      "metadata": {
        "id": "pYT3RQNpIsSx"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "r4DdA9moGb0H"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def linear_beta_schedule(timesteps, start=0.0001, end=0.02):\n",
        "    return torch.linspace(start, end, timesteps)\n",
        "\n",
        "def get_index_from_list(vals, t, x_shape):\n",
        "    \"\"\"\n",
        "    Returns a specific index t of a passed list of values vals\n",
        "    while considering the batch dimension.\n",
        "    \"\"\"\n",
        "    batch_size = t.shape[0]\n",
        "    out = vals.gather(-1, t.cpu())\n",
        "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n",
        "\n",
        "def forward_diffusion_sample(x_0, t, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    Takes an image and a timestep as input and\n",
        "    returns the noisy version of it\n",
        "    \"\"\"\n",
        "    noise = torch.randn_like(x_0)\n",
        "    sqrt_alphas_cumprod_t = get_index_from_list(sqrt_alphas_cumprod, t, x_0.shape)\n",
        "    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(\n",
        "        sqrt_one_minus_alphas_cumprod, t, x_0.shape\n",
        "    )\n",
        "    # mean + variance\n",
        "    return sqrt_alphas_cumprod_t.to(device) * x_0.to(device) \\\n",
        "    + sqrt_one_minus_alphas_cumprod_t.to(device) * noise.to(device), noise.to(device)\n",
        "\n",
        "\n",
        "# Define beta schedule\n",
        "T = 300\n",
        "betas = linear_beta_schedule(timesteps=T)\n",
        "\n",
        "# Pre-calculate different terms for closed form\n",
        "alphas = 1. - betas\n",
        "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
        "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
        "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
        "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
        "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)"
      ],
      "metadata": {
        "id": "7-I7muJXGjTN"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import math\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, time_emb_dim, up=False):\n",
        "        super().__init__()\n",
        "        self.time_mlp =  nn.Linear(time_emb_dim, out_ch)\n",
        "        if up:\n",
        "            self.dense1=nn.Linear(in_ch*2,out_ch)\n",
        "        else:\n",
        "            self.dense1=nn.Linear(in_ch,out_ch)\n",
        "        self.dense2 = nn.Linear(out_ch, out_ch)\n",
        "        self.transform=nn.Linear(out_ch,out_ch)\n",
        "        self.bnorm1 = nn.BatchNorm1d(out_ch)\n",
        "        self.bnorm2 = nn.BatchNorm1d(out_ch)\n",
        "        self.relu  = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, t, ):\n",
        "        # First Conv\n",
        "        h = self.bnorm1(self.relu(self.dense1(x)))\n",
        "        # Time embedding\n",
        "        time_emb = self.relu(self.time_mlp(t))\n",
        "        # Extend last 2 dimensions\n",
        "        # time_emb = time_emb[(..., ) + (None, ) * 2]\n",
        "        # Add time channel\n",
        "        h = h + time_emb\n",
        "        # Second Conv\n",
        "        h = self.bnorm2(self.relu(self.dense2(h)))\n",
        "        # Down or Upsample\n",
        "        return self.transform(h)\n",
        "\n",
        "\n",
        "class SinusoidalPositionEmbeddings(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, time):\n",
        "        device = time.device\n",
        "        half_dim = self.dim // 2\n",
        "        embeddings = math.log(10000) / (half_dim - 1)\n",
        "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
        "        embeddings = time[:, None] * embeddings[None, :]\n",
        "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
        "        # TODO: Double check the ordering here\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class SimpleUnet(nn.Module):\n",
        "    \"\"\"\n",
        "    A simplified variant of the Unet architecture.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        down_channels = (2048, 1024, 512, 256, 128)\n",
        "        up_channels = (128, 256, 512, 1024, 2048)\n",
        "\n",
        "        out_dim = dataset[0]['x'].shape[0]\n",
        "        time_emb_dim = 32\n",
        "        f_dim=dataset[0]['x'].shape[0]\n",
        "        # Time embedding\n",
        "        self.time_mlp = nn.Sequential(\n",
        "                SinusoidalPositionEmbeddings(time_emb_dim),\n",
        "                nn.Linear(time_emb_dim, time_emb_dim),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "\n",
        "        # Initial projection\n",
        "        self.dense0 = nn.Linear(f_dim, down_channels[0])\n",
        "\n",
        "        # Downsample\n",
        "        self.downs = nn.ModuleList([Block(down_channels[i], down_channels[i+1], \\\n",
        "                                    time_emb_dim) \\\n",
        "                    for i in range(len(down_channels)-1)])\n",
        "        # Upsample\n",
        "        self.ups = nn.ModuleList([Block(up_channels[i], up_channels[i+1], \\\n",
        "                                        time_emb_dim, up=True) \\\n",
        "                    for i in range(len(up_channels)-1)])\n",
        "\n",
        "        # Edit: Corrected a bug found by Jakub C (see YouTube comment)\n",
        "        self.output = nn.Linear(up_channels[-1], out_dim)\n",
        "\n",
        "    def forward(self, x, timestep):\n",
        "        # Embedd time\n",
        "        t = self.time_mlp(timestep)\n",
        "        # Initial conv\n",
        "        x = self.dense0(x)\n",
        "        # Unet\n",
        "        residual_inputs = []\n",
        "        for down in self.downs:\n",
        "            x = down(x, t)\n",
        "            residual_inputs.append(x)\n",
        "        for up in self.ups:\n",
        "            residual_x = residual_inputs.pop()\n",
        "            # Add residual x as additional channels\n",
        "            x = torch.cat((x, residual_x), dim=1)\n",
        "            x = up(x, t)\n",
        "        return self.output(x)\n",
        "\n",
        "model = SimpleUnet()\n",
        "print(\"Num params: \", sum(p.numel() for p in model.parameters()))\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mUIjowsGmoJ",
        "outputId": "0cadc88d-36ac-492d-ec02-59a0ee35287f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-90b3a69ead71>:7: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
            "  return {'x':torch.tensor((self.data.X[idx]-mean_)/std_),'c':torch.tensor(self.data.obs.iloc[idx]['core_control'])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num params:  58360397\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleUnet(\n",
              "  (time_mlp): Sequential(\n",
              "    (0): SinusoidalPositionEmbeddings()\n",
              "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (dense0): Linear(in_features=8749, out_features=2048, bias=True)\n",
              "  (downs): ModuleList(\n",
              "    (0): Block(\n",
              "      (time_mlp): Linear(in_features=32, out_features=1024, bias=True)\n",
              "      (dense1): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "      (dense2): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (transform): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (bnorm1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bnorm2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block(\n",
              "      (time_mlp): Linear(in_features=32, out_features=512, bias=True)\n",
              "      (dense1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "      (dense2): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (transform): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (bnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block(\n",
              "      (time_mlp): Linear(in_features=32, out_features=256, bias=True)\n",
              "      (dense1): Linear(in_features=512, out_features=256, bias=True)\n",
              "      (dense2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (transform): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (bnorm1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bnorm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block(\n",
              "      (time_mlp): Linear(in_features=32, out_features=128, bias=True)\n",
              "      (dense1): Linear(in_features=256, out_features=128, bias=True)\n",
              "      (dense2): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (transform): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (bnorm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (ups): ModuleList(\n",
              "    (0): Block(\n",
              "      (time_mlp): Linear(in_features=32, out_features=256, bias=True)\n",
              "      (dense1): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (dense2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (transform): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (bnorm1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bnorm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block(\n",
              "      (time_mlp): Linear(in_features=32, out_features=512, bias=True)\n",
              "      (dense1): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (dense2): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (transform): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (bnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block(\n",
              "      (time_mlp): Linear(in_features=32, out_features=1024, bias=True)\n",
              "      (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (dense2): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (transform): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (bnorm1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bnorm2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block(\n",
              "      (time_mlp): Linear(in_features=32, out_features=2048, bias=True)\n",
              "      (dense1): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "      (dense2): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "      (transform): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "      (bnorm1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bnorm2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (output): Linear(in_features=2048, out_features=8749, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss(model, x_0, t):\n",
        "    x_noisy, noise = forward_diffusion_sample(x_0, t, device)\n",
        "    noise_pred = model(x_noisy, t)\n",
        "    return F.l1_loss(noise, noise_pred)"
      ],
      "metadata": {
        "id": "2SOxKDKPHy2g"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def sample_timestep(x, t):\n",
        "    \"\"\"\n",
        "    Calls the model to predict the noise in the image and returns\n",
        "    the denoised image.\n",
        "    Applies noise to this image, if we are not in the last step yet.\n",
        "    \"\"\"\n",
        "    betas_t = get_index_from_list(betas, t, x.shape)\n",
        "    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(\n",
        "        sqrt_one_minus_alphas_cumprod, t, x.shape\n",
        "    )\n",
        "    sqrt_recip_alphas_t = get_index_from_list(sqrt_recip_alphas, t, x.shape)\n",
        "\n",
        "    # Call model (current image - noise prediction)\n",
        "    model_mean = sqrt_recip_alphas_t * (\n",
        "        x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t\n",
        "    )\n",
        "    posterior_variance_t = get_index_from_list(posterior_variance, t, x.shape)\n",
        "\n",
        "    if t == 0:\n",
        "        # As pointed out by Luis Pereira (see YouTube comment)\n",
        "        # The t's are offset from the t's in the paper\n",
        "        return model_mean\n",
        "    else:\n",
        "        noise = torch.randn_like(x)\n",
        "        return model_mean + torch.sqrt(posterior_variance_t) * noise\n"
      ],
      "metadata": {
        "id": "9xCD4PnEJL0l"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "epochs = 1000 # Try more!\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for step, batch in tqdm.tqdm(enumerate(train_loader)):\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      t = torch.randint(0, T, (32,), device=device).long()\n",
        "      loss = get_loss(model, batch['x'], t)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if epoch % 5 == 0 and step == 0:\n",
        "        print(f\"Epoch {epoch} | step {step:03d} Loss: {loss.item()} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPpuFfo2JMU1",
        "outputId": "3c6fd3f3-3b10-49a2-937b-d19afd4188c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]<ipython-input-36-90b3a69ead71>:7: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
            "  return {'x':torch.tensor((self.data.X[idx]-mean_)/std_),'c':torch.tensor(self.data.obs.iloc[idx]['core_control'])}\n",
            "7it [00:00, 30.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | step 000 Loss: 0.8412640690803528 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "83it [00:02, 31.98it/s]\n",
            "83it [00:02, 28.66it/s]\n",
            "83it [00:02, 31.51it/s]\n",
            "83it [00:02, 32.17it/s]\n",
            "83it [00:02, 32.29it/s]\n",
            "4it [00:00, 30.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 | step 000 Loss: 0.8129385113716125 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "83it [00:02, 31.77it/s]\n",
            "83it [00:02, 28.99it/s]\n",
            "83it [00:02, 32.54it/s]\n",
            "83it [00:02, 32.42it/s]\n",
            "83it [00:02, 32.09it/s]\n",
            "7it [00:00, 30.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 | step 000 Loss: 0.8101053833961487 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "83it [00:02, 29.49it/s]\n",
            "83it [00:03, 25.17it/s]\n",
            "83it [00:02, 31.87it/s]\n",
            "83it [00:02, 31.93it/s]\n",
            "83it [00:02, 31.30it/s]\n",
            "6it [00:00, 27.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 | step 000 Loss: 0.805308997631073 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "83it [00:02, 29.16it/s]\n",
            "83it [00:02, 31.93it/s]\n",
            "83it [00:02, 32.26it/s]\n",
            "83it [00:02, 32.29it/s]\n",
            "83it [00:02, 29.40it/s]\n",
            "6it [00:00, 24.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 | step 000 Loss: 0.8008050918579102 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "83it [00:02, 30.92it/s]\n",
            "83it [00:02, 31.86it/s]\n",
            "83it [00:02, 32.02it/s]\n",
            "83it [00:02, 31.98it/s]\n",
            "83it [00:02, 28.76it/s]\n",
            "7it [00:00, 30.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 | step 000 Loss: 0.7984899282455444 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "83it [00:02, 31.94it/s]\n",
            "83it [00:02, 31.99it/s]\n",
            "83it [00:02, 32.19it/s]\n",
            "83it [00:02, 29.91it/s]\n",
            "83it [00:02, 30.63it/s]\n",
            "4it [00:00, 31.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 | step 000 Loss: 0.7982907891273499 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "83it [00:02, 32.36it/s]\n",
            "83it [00:02, 32.35it/s]\n",
            "83it [00:02, 32.37it/s]\n",
            "83it [00:02, 28.67it/s]\n",
            "83it [00:02, 31.82it/s]\n",
            "7it [00:00, 31.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35 | step 000 Loss: 0.797542929649353 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "83it [00:02, 32.16it/s]\n",
            "83it [00:02, 32.14it/s]\n",
            "83it [00:02, 29.91it/s]\n",
            "83it [00:02, 30.19it/s]\n",
            "83it [00:02, 31.49it/s]\n",
            "6it [00:00, 29.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40 | step 000 Loss: 0.7986546754837036 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "34it [00:01, 30.74it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i8KrzUpnJeSZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}