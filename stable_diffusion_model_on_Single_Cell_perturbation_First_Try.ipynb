{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scanpy --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkxK46YGGGI6",
        "outputId": "48cec299-a6ef-44ea-ab94-26a486bc75c3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for session-info (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://plus.figshare.com/ndownloader/files/35775512"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lHLb9eHGPvq",
        "outputId": "190632ad-e005-4aa4-bbf0-04303abeec1e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-25 21:16:21--  https://plus.figshare.com/ndownloader/files/35775512\n",
            "Resolving plus.figshare.com (plus.figshare.com)... 54.155.30.132, 34.248.227.16, 2a05:d018:1f4:d000:ae86:39bc:5e7b:c384, ...\n",
            "Connecting to plus.figshare.com (plus.figshare.com)|54.155.30.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://s3-eu-west-1.amazonaws.com/pstorage-plus-7003492043/35775512/rpe1_normalized_bulk_01.h5ad?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA3OGA3B5WLN3GODUZ/20240125/eu-west-1/s3/aws4_request&X-Amz-Date=20240125T211621Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=3dd2c2ffe9e064128cbfede2f464429fc06fe2fc9bc7878a928204b54e8f7408 [following]\n",
            "--2024-01-25 21:16:21--  https://s3-eu-west-1.amazonaws.com/pstorage-plus-7003492043/35775512/rpe1_normalized_bulk_01.h5ad?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA3OGA3B5WLN3GODUZ/20240125/eu-west-1/s3/aws4_request&X-Amz-Date=20240125T211621Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=3dd2c2ffe9e064128cbfede2f464429fc06fe2fc9bc7878a928204b54e8f7408\n",
            "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.90.91, 52.218.117.64, 52.218.25.51, ...\n",
            "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.90.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 95350546 (91M) [application/octet-stream]\n",
            "Saving to: ‘35775512’\n",
            "\n",
            "35775512            100%[===================>]  90.93M  15.9MB/s    in 7.0s    \n",
            "\n",
            "2024-01-25 21:16:29 (12.9 MB/s) - ‘35775512’ saved [95350546/95350546]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RrTy4V5PEAXx"
      },
      "outputs": [],
      "source": [
        "import scanpy as sc\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adata_orig = sc.read_h5ad(\"35775512\")\n",
        "adata_orig.X[adata_orig.X == float(\"inf\")]=0"
      ],
      "metadata": {
        "id": "YlPlde8NGBam"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import plotly.express as px\n",
        "n_components=10\n",
        "pca = PCA(n_components=n_components)\n",
        "pca.fit(adata_orig.X)\n",
        "\n",
        "new_X=pca.transform(adata_orig.X)"
      ],
      "metadata": {
        "id": "yoT0PAFFh2sa"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# min_=adata_orig.X.min(axis=0)\n",
        "# max_=adata_orig.X.max(axis=0)\n",
        "min_=new_X.min(axis=0)\n",
        "max_=new_X.max(axis=0)\n",
        "\n",
        "diff_=(max_-min_)/2\n",
        "mid_=(max_+min_)/2"
      ],
      "metadata": {
        "id": "8kGzU6OxT2te"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import tqdm\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "\n",
        "\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
      ],
      "metadata": {
        "id": "7v1T3KqDGLV7"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class X_dataset(Dataset):\n",
        "    def __init__(self,data):\n",
        "        self.data=data\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        return {'x':torch.tensor((new_X[idx]-mid_)/diff_),'c':torch.tensor(self.data.obs.iloc[idx]['core_control'])}\n"
      ],
      "metadata": {
        "id": "xWjJL1iDIqDY"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=X_dataset(adata_orig)\n",
        "train_loader=DataLoader(dataset,batch_size=32,shuffle=True,drop_last=True)"
      ],
      "metadata": {
        "id": "pYT3RQNpIsSx"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "r4DdA9moGb0H"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def linear_beta_schedule(timesteps, start=0.0001, end=0.02):\n",
        "    return torch.linspace(start, end, timesteps)\n",
        "\n",
        "def get_index_from_list(vals, t, x_shape):\n",
        "    \"\"\"\n",
        "    Returns a specific index t of a passed list of values vals\n",
        "    while considering the batch dimension.\n",
        "    \"\"\"\n",
        "    batch_size = t.shape[0]\n",
        "    out = vals.gather(-1, t.cpu())\n",
        "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n",
        "\n",
        "def forward_diffusion_sample(x_0, t, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    Takes an image and a timestep as input and\n",
        "    returns the noisy version of it\n",
        "    \"\"\"\n",
        "    noise = torch.randn_like(x_0)\n",
        "    sqrt_alphas_cumprod_t = get_index_from_list(sqrt_alphas_cumprod, t, x_0.shape)\n",
        "    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(\n",
        "        sqrt_one_minus_alphas_cumprod, t, x_0.shape\n",
        "    )\n",
        "    # mean + variance\n",
        "    return sqrt_alphas_cumprod_t.to(device) * x_0.to(device) \\\n",
        "    + sqrt_one_minus_alphas_cumprod_t.to(device) * noise.to(device), noise.to(device)\n",
        "\n",
        "\n",
        "# Define beta schedule\n",
        "T = 300\n",
        "betas = linear_beta_schedule(timesteps=T)\n",
        "\n",
        "# Pre-calculate different terms for closed form\n",
        "alphas = 1. - betas\n",
        "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
        "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
        "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
        "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
        "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)"
      ],
      "metadata": {
        "id": "7-I7muJXGjTN"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import math\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, time_emb_dim, up=False):\n",
        "        super().__init__()\n",
        "        self.time_mlp =  nn.Linear(time_emb_dim, out_ch)\n",
        "        if up:\n",
        "            self.dense1=nn.Linear(in_ch*2,out_ch)\n",
        "        else:\n",
        "            self.dense1=nn.Linear(in_ch,out_ch)\n",
        "        self.dense2 = nn.Linear(out_ch, out_ch)\n",
        "        self.transform=nn.Linear(out_ch,out_ch)\n",
        "        self.bnorm1 = nn.BatchNorm1d(out_ch)\n",
        "        self.bnorm2 = nn.BatchNorm1d(out_ch)\n",
        "        self.relu  = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, t, ):\n",
        "        # First Conv\n",
        "        h = self.bnorm1(self.relu(self.dense1(x)))\n",
        "        # print(h.shape)\n",
        "        # Time embedding\n",
        "        # print(t.shape)\n",
        "        time_emb = self.relu(self.time_mlp(t))\n",
        "        # print(time_emb.shape)\n",
        "        # Extend last 2 dimensions\n",
        "        # time_emb = time_emb[(..., ) + (None, ) * 2]\n",
        "        # Add time channel\n",
        "        h = h + time_emb\n",
        "        # Second Conv\n",
        "        h = self.bnorm2(self.relu(self.dense2(h)))\n",
        "        # Down or Upsample\n",
        "        return self.transform(h)\n",
        "\n",
        "\n",
        "class SinusoidalPositionEmbeddings(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, time):\n",
        "        device = time.device\n",
        "        half_dim = self.dim // 2\n",
        "        embeddings = math.log(10000) / (half_dim - 1)\n",
        "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
        "        embeddings = time[:, None] * embeddings[None, :]\n",
        "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
        "        # TODO: Double check the ordering here\n",
        "        # print(embeddings.shape)\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class SimpleUnet(nn.Module):\n",
        "    \"\"\"\n",
        "    A simplified variant of the Unet architecture.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        down_channels = (1024, 512, 256, 128, 64)\n",
        "        up_channels = (64, 128, 256, 512, 1024)\n",
        "        # down_channels = (1024, 512, 256)\n",
        "        # up_channels = (256, 512, 1024)\n",
        "        out_dim = dataset[0]['x'].shape[0]\n",
        "        time_emb_dim = 64\n",
        "        f_dim=dataset[0]['x'].shape[0]\n",
        "        # Time embedding\n",
        "        self.time_mlp = nn.Sequential(\n",
        "                SinusoidalPositionEmbeddings(time_emb_dim),\n",
        "                nn.Linear(time_emb_dim, time_emb_dim),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "\n",
        "        # Initial projection\n",
        "        self.dense0 = nn.Linear(f_dim, down_channels[0])\n",
        "\n",
        "        # Downsample\n",
        "        self.downs = nn.ModuleList([Block(down_channels[i], down_channels[i+1], \\\n",
        "                                    time_emb_dim) \\\n",
        "                    for i in range(len(down_channels)-1)])\n",
        "        # Upsample\n",
        "        self.ups = nn.ModuleList([Block(up_channels[i], up_channels[i+1], \\\n",
        "                                        time_emb_dim, up=True) \\\n",
        "                    for i in range(len(up_channels)-1)])\n",
        "\n",
        "        # Edit: Corrected a bug found by Jakub C (see YouTube comment)\n",
        "        self.output = nn.Linear(up_channels[-1], out_dim)\n",
        "\n",
        "    def forward(self, x, timestep):\n",
        "        # Embedd time\n",
        "        # print(timestep.shape)\n",
        "        t = self.time_mlp(timestep)\n",
        "        # Initial conv\n",
        "        x = self.dense0(x)\n",
        "        # Unet\n",
        "        residual_inputs = []\n",
        "        for down in self.downs:\n",
        "            x = down(x, t)\n",
        "            residual_inputs.append(x)\n",
        "        for up in self.ups:\n",
        "            residual_x = residual_inputs.pop()\n",
        "            # Add residual x as additional channels\n",
        "            x = torch.cat((x, residual_x), dim=1)\n",
        "            x = up(x, t)\n",
        "        return self.output(x)\n",
        "\n",
        "model = SimpleUnet()\n",
        "print(\"Num params: \", sum(p.numel() for p in model.parameters()))\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mUIjowsGmoJ",
        "outputId": "0594e96a-f2af-4928-f899-7aa493189f66"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num params:  5803594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-96625bde485d>:7: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
            "  return {'x':torch.tensor((new_X[idx]-mid_)/diff_),'c':torch.tensor(self.data.obs.iloc[idx]['core_control'])}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleUnet(\n",
              "  (time_mlp): Sequential(\n",
              "    (0): SinusoidalPositionEmbeddings()\n",
              "    (1): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (dense0): Linear(in_features=10, out_features=1024, bias=True)\n",
              "  (downs): ModuleList(\n",
              "    (0): Block(\n",
              "      (time_mlp): Linear(in_features=64, out_features=512, bias=True)\n",
              "      (dense1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "      (dense2): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (transform): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (bnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block(\n",
              "      (time_mlp): Linear(in_features=64, out_features=256, bias=True)\n",
              "      (dense1): Linear(in_features=512, out_features=256, bias=True)\n",
              "      (dense2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (transform): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (bnorm1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bnorm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block(\n",
              "      (time_mlp): Linear(in_features=64, out_features=128, bias=True)\n",
              "      (dense1): Linear(in_features=256, out_features=128, bias=True)\n",
              "      (dense2): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (transform): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (bnorm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block(\n",
              "      (time_mlp): Linear(in_features=64, out_features=64, bias=True)\n",
              "      (dense1): Linear(in_features=128, out_features=64, bias=True)\n",
              "      (dense2): Linear(in_features=64, out_features=64, bias=True)\n",
              "      (transform): Linear(in_features=64, out_features=64, bias=True)\n",
              "      (bnorm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bnorm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (ups): ModuleList(\n",
              "    (0): Block(\n",
              "      (time_mlp): Linear(in_features=64, out_features=128, bias=True)\n",
              "      (dense1): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (dense2): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (transform): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (bnorm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block(\n",
              "      (time_mlp): Linear(in_features=64, out_features=256, bias=True)\n",
              "      (dense1): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (dense2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (transform): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (bnorm1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bnorm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block(\n",
              "      (time_mlp): Linear(in_features=64, out_features=512, bias=True)\n",
              "      (dense1): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (dense2): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (transform): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (bnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bnorm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block(\n",
              "      (time_mlp): Linear(in_features=64, out_features=1024, bias=True)\n",
              "      (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (dense2): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (transform): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (bnorm1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bnorm2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (output): Linear(in_features=1024, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss(model, x_0, t):\n",
        "    x_noisy, noise = forward_diffusion_sample(x_0, t, device)\n",
        "    noise_pred = model(x_noisy, t)\n",
        "    return F.l1_loss(noise, noise_pred)"
      ],
      "metadata": {
        "id": "2SOxKDKPHy2g"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def sample_timestep(x, t):\n",
        "    \"\"\"\n",
        "    Calls the model to predict the noise in the image and returns\n",
        "    the denoised image.\n",
        "    Applies noise to this image, if we are not in the last step yet.\n",
        "    \"\"\"\n",
        "    betas_t = get_index_from_list(betas, t, x.shape)\n",
        "    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(\n",
        "        sqrt_one_minus_alphas_cumprod, t, x.shape\n",
        "    )\n",
        "    sqrt_recip_alphas_t = get_index_from_list(sqrt_recip_alphas, t, x.shape)\n",
        "\n",
        "    # Call model (current image - noise prediction)\n",
        "    model_mean = sqrt_recip_alphas_t * (\n",
        "        x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t\n",
        "    )\n",
        "    posterior_variance_t = get_index_from_list(posterior_variance, t, x.shape)\n",
        "\n",
        "    if t == 0:\n",
        "        # As pointed out by Luis Pereira (see YouTube comment)\n",
        "        # The t's are offset from the t's in the paper\n",
        "        return model_mean\n",
        "    else:\n",
        "        noise = torch.randn_like(x)\n",
        "        return model_mean + torch.sqrt(posterior_variance_t) * noise\n"
      ],
      "metadata": {
        "id": "9xCD4PnEJL0l"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "epochs = 1000 # Try more!\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss=0\n",
        "    for step, batch in tqdm.tqdm(enumerate(train_loader)):\n",
        "      optimizer.zero_grad()\n",
        "      t = torch.randint(0, T, (32,), device=device).long()\n",
        "      loss = get_loss(model, batch['x'], t)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      total_loss+=loss.item()\n",
        "    if epoch % 5 == 0:\n",
        "      print(f\"Epoch {epoch} | step {step:03d} Loss: {total_loss/len(train_loader)} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CPpuFfo2JMU1",
        "outputId": "0a48c9bc-9682-4e46-90ac-13208bbf57cf"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]<ipython-input-39-96625bde485d>:7: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
            "  return {'x':torch.tensor((new_X[idx]-mid_)/diff_),'c':torch.tensor(self.data.obs.iloc[idx]['core_control'])}\n",
            "83it [00:01, 54.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | step 082 Loss: 0.5761066183268305 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "83it [00:01, 51.86it/s]\n",
            "83it [00:01, 53.28it/s]\n",
            "83it [00:01, 54.65it/s]\n",
            "83it [00:01, 55.00it/s]\n",
            "83it [00:01, 42.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 | step 082 Loss: 0.33239123153399275 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "83it [00:01, 52.30it/s]\n",
            "83it [00:01, 53.39it/s]\n",
            "83it [00:01, 54.84it/s]\n",
            "83it [00:01, 54.54it/s]\n",
            "83it [00:01, 54.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 | step 082 Loss: 0.3071428361427353 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "83it [00:01, 54.69it/s]\n",
            "83it [00:01, 47.35it/s]\n",
            "83it [00:01, 43.60it/s]\n",
            "83it [00:01, 54.99it/s]\n",
            "83it [00:01, 54.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 | step 082 Loss: 0.29256009319460535 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "83it [00:01, 54.61it/s]\n",
            "83it [00:01, 55.38it/s]\n",
            "83it [00:01, 55.11it/s]\n",
            "83it [00:01, 55.96it/s]\n",
            "83it [00:02, 38.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 | step 082 Loss: 0.2822795027350805 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "83it [00:01, 56.63it/s]\n",
            "83it [00:01, 57.93it/s]\n",
            "83it [00:01, 55.29it/s]\n",
            "83it [00:01, 56.10it/s]\n",
            "83it [00:01, 55.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 | step 082 Loss: 0.2864609480981367 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "83it [00:01, 54.87it/s]\n",
            "83it [00:01, 47.21it/s]\n",
            "83it [00:01, 44.57it/s]\n",
            "83it [00:01, 55.00it/s]\n",
            "83it [00:01, 54.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 | step 082 Loss: 0.28405559134770586 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "83it [00:01, 56.80it/s]\n",
            "83it [00:01, 55.10it/s]\n",
            "83it [00:01, 55.79it/s]\n",
            "83it [00:01, 56.92it/s]\n",
            "83it [00:01, 42.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35 | step 082 Loss: 0.27552519397563247 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "83it [00:01, 52.60it/s]\n",
            "83it [00:01, 55.87it/s]\n",
            "83it [00:01, 54.94it/s]\n",
            "83it [00:01, 54.64it/s]\n",
            "83it [00:01, 53.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40 | step 082 Loss: 0.2729438232729234 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "83it [00:01, 54.45it/s]\n",
            "83it [00:01, 45.83it/s]\n",
            "83it [00:01, 44.42it/s]\n",
            "6it [00:00, 45.61it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-3c75109c9cfa>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mtotal_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.l1_loss()"
      ],
      "metadata": {
        "id": "R9Y8hovwIWVo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "8184cc65-27b8-4546-88b5-2803b500ed4b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'int' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-6b2c01e4640e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36ml1_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3285\u001b[0m             \u001b[0ml1_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3286\u001b[0m         )\n\u001b[0;32m-> 3287\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3288\u001b[0m         warnings.warn(\n\u001b[1;32m   3289\u001b[0m             \u001b[0;34mf\"Using a target size ({target.size()}) that is different to the input size ({input.size()}). \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
          ]
        }
      ]
    }
  ]
}